{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dlc_practical_prologue as plg\n",
    "from torch import nn, LongTensor\n",
    "from torch.nn import functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        nb_hidden = 100\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = self.fc1(x.view(-1, 16 * 6 * 6))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(2 * 2 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = plg.generate_pair_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_left = train_input[:,0,:,:].view(N,1,14,14)\n",
    "train_classes_left = plg.convert_to_one_hot_labels(train_input, train_classes[:,0]).type(LongTensor)\n",
    "test_input_left = test_input[:,0,:,:].view(N,1,14,14)\n",
    "test_classes_left = plg.convert_to_one_hot_labels(test_input, test_classes[:,0]).type(LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    \n",
    "    if (torch.cuda.is_available()):\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    model.to(device)\n",
    "    train_input = train_input.to(device)\n",
    "    train_target = train_target.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    #criterion = nn.MSELoss().to(device)\n",
    "    eta = 1e-1\n",
    "    epochs = 50\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = eta)\n",
    "    \n",
    "    for e in range(0, epochs):\n",
    "        for input_data, target_data in zip(train_input.split(mini_batch_size), train_target.split(mini_batch_size)):\n",
    "            output = model(input_data)\n",
    "            loss = criterion(output, target_data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_one_hot(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        act_classes = target.narrow(0, b, mini_batch_size).max(1)[1]\n",
    "        for k in range(mini_batch_size):\n",
    "            if act_classes[k] != predicted_classes[k]:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[k] != predicted_classes[k]:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net2()\n",
    "train_model(model, train_input_left, train_classes[:,0], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4401"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, test_input_left, test_classes[:,0], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4454"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, train_input_left, train_classes[:,0], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-186)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(train_input_left).max(1)[1] - train_classes[:,0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+KWiDL9UlOGXijL8UlH/BzeHofFaFp1gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aa58080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input_left[2000,0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
