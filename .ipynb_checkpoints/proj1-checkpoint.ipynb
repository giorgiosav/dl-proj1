{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue as plg\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from operator import mul as multiplicator\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (torch.cuda.is_available()):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = plg.generate_pair_sets(N)\n",
    "train_input = train_input.to(device)\n",
    "train_target = train_target.to(device)\n",
    "train_classes = train_classes.to(device)\n",
    "test_input = test_input.to(device)\n",
    "test_target = test_target.to(device)\n",
    "test_classes = test_classes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "train_input = train_input.sub(mu).div(std)\n",
    "test_input = test_input.sub(mu).div(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: simple network trained with cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden1 = 50, nb_hidden2 = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=3, padding=2)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, dilation=1)\n",
    "        #self.conv3 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, nb_hidden1)\n",
    "        self.fc2 = nn.Linear(nb_hidden1, nb_hidden2)\n",
    "        self.fc3 = nn.Linear(nb_hidden2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.avgpool1(self.conv1(x)))\n",
    "        x = F.relu(self.maxpool1(self.conv2(x)))\n",
    "        x = F.relu(self.fc1(x.view(-1, 16*3*3)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden1 = 50, nb_hidden2 = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=3, groups=2)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, dilation=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32*2*2, nb_hidden1)\n",
    "        self.fc2 = nn.Linear(nb_hidden1, nb_hidden2)\n",
    "        self.fc3 = nn.Linear(nb_hidden2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.maxpool1(self.conv1(x)))\n",
    "        x = F.relu(self.maxpool2(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 32*2*2)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), groups=2) output shape:\t torch.Size([1, 8, 12, 12])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) output shape:\t torch.Size([1, 8, 6, 6])\n",
      "Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) output shape:\t torch.Size([1, 16, 6, 6])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) output shape:\t torch.Size([1, 16, 3, 3])\n",
      "Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1)) output shape:\t torch.Size([1, 32, 2, 2])\n",
      "Linear(in_features=128, out_features=50, bias=True) output shape:\t torch.Size([1, 50])\n",
      "Linear(in_features=50, out_features=10, bias=True) output shape:\t torch.Size([1, 10])\n",
      "Linear(in_features=10, out_features=2, bias=True) output shape:\t torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Check on the sizes\n",
    "X = torch.empty((1, 2, 14, 14)).normal_()\n",
    "net = Net()\n",
    "for layer in net.children():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        X = X.view(-1, reduce(multiplicator, list(X.shape[1:])))\n",
    "    X = layer(X)\n",
    "    print(layer, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta, optim=\"SGD\", momentum = 0, nesterov = False):\n",
    "    \n",
    "    if (optim == \"SGD\"):\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = eta, momentum = momentum, nesterov = nesterov)\n",
    "    if (optim == \"Adam\"):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "        \n",
    "    for e in range(0, epochs):\n",
    "        for input_data, target_data in zip(train_input.split(mini_batch_size), train_target.split(mini_batch_size)):\n",
    "            output = model(input_data)\n",
    "            loss = criterion(output, target_data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target, mini_batch_size):\n",
    "    tot_err = 0\n",
    "    for input_data, target_data in zip(data_input.split(mini_batch_size), data_target.split(mini_batch_size)):\n",
    "        res = model(input_data)\n",
    "        for i, r in enumerate(res):\n",
    "            pred = r.max(0)[1].item()\n",
    "            if(target_data[i])!=pred:\n",
    "                tot_err+=1\n",
    "    return tot_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 250\n",
    "eta = 0.01\n",
    "train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, train_input, train_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, test_input, test_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize over eta (simple optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta = 1e-05, avg_err = 530.0\n",
      "Eta = 0.0001, avg_err = 509.5\n",
      "Eta = 0.001, avg_err = 456.1\n",
      "Eta = 0.01, avg_err = 224.5\n",
      "Eta = 0.1, avg_err = 350.5\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 100\n",
    "etas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "N = 10\n",
    "for eta in etas:\n",
    "    tot_eta = 0\n",
    "    for i in range(0, N):\n",
    "        train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta)\n",
    "        err = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "        tot_eta+=err\n",
    "    print(\"Eta = {}, avg_err = {}\".format(eta, tot_eta/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize over eta, momentum, nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta = 0.0001, momentum = 0.0001, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.0001, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.001, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.001, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.01, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.01, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.1, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.1, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.0001, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.0001, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.001, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.001, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.01, nesterov = False, avg_err = 469.6666666666667\n",
      "Eta = 0.001, momentum = 0.01, nesterov = True, avg_err = 409.6666666666667\n",
      "Eta = 0.001, momentum = 0.1, nesterov = False, avg_err = 319.3333333333333\n",
      "Eta = 0.001, momentum = 0.1, nesterov = True, avg_err = 279.6666666666667\n",
      "Eta = 0.01, momentum = 0.0001, nesterov = False, avg_err = 228.0\n",
      "Eta = 0.01, momentum = 0.0001, nesterov = True, avg_err = 206.33333333333334\n",
      "Eta = 0.01, momentum = 0.001, nesterov = False, avg_err = 207.0\n",
      "Eta = 0.01, momentum = 0.001, nesterov = True, avg_err = 207.66666666666666\n",
      "Eta = 0.01, momentum = 0.01, nesterov = False, avg_err = 206.66666666666666\n",
      "Eta = 0.01, momentum = 0.01, nesterov = True, avg_err = 206.0\n",
      "Eta = 0.01, momentum = 0.1, nesterov = False, avg_err = 207.0\n",
      "Eta = 0.01, momentum = 0.1, nesterov = True, avg_err = 207.0\n",
      "Eta = 0.1, momentum = 0.0001, nesterov = False, avg_err = 206.66666666666666\n",
      "Eta = 0.1, momentum = 0.0001, nesterov = True, avg_err = 206.0\n",
      "Eta = 0.1, momentum = 0.001, nesterov = False, avg_err = 206.66666666666666\n",
      "Eta = 0.1, momentum = 0.001, nesterov = True, avg_err = 206.33333333333334\n",
      "Eta = 0.1, momentum = 0.01, nesterov = False, avg_err = 204.66666666666666\n",
      "Eta = 0.1, momentum = 0.01, nesterov = True, avg_err = 204.0\n",
      "Eta = 0.1, momentum = 0.1, nesterov = False, avg_err = 205.0\n",
      "Eta = 0.1, momentum = 0.1, nesterov = True, avg_err = 206.0\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 100\n",
    "etas = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "momentum = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "N = 3\n",
    "for eta in etas:\n",
    "    for m in momentum:\n",
    "        for nest in [False, True]:\n",
    "            tot_eta = 0\n",
    "            for i in range(0, N):\n",
    "                train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta, \"SGD\", m, nest)\n",
    "                err = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "                tot_eta+=err\n",
    "            print(\"Eta = {}, momentum = {}, nesterov = {}, avg_err = {}\".format(eta, m, nest, tot_eta/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 250\n",
    "eta = 0.01\n",
    "train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta, \"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, train_input, train_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, test_input, test_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize over eta (simple optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta = 1e-05, avg_err = 325.2\n",
      "Eta = 0.0001, avg_err = 235.6\n",
      "Eta = 0.001, avg_err = 234.2\n",
      "Eta = 0.01, avg_err = 236.5\n",
      "Eta = 0.1, avg_err = 470.0\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 100\n",
    "etas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "N = 10\n",
    "for eta in etas:\n",
    "    tot_eta = 0\n",
    "    for i in range(0, N):\n",
    "        train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta, \"Adam\")\n",
    "        err = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "        tot_eta+=err\n",
    "    print(\"Eta = {}, avg_err = {}\".format(eta, tot_eta/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 250\n",
    "eta = 0.01\n",
    "train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, train_input, train_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, test_input, test_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize over eta (simple optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta = 1e-05, avg_err = 530.0\n",
      "Eta = 0.0001, avg_err = 530.0\n",
      "Eta = 0.001, avg_err = 470.0\n",
      "Eta = 0.01, avg_err = 252.5\n",
      "Eta = 0.1, avg_err = 229.7\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 100\n",
    "etas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "N = 10\n",
    "for eta in etas:\n",
    "    tot_eta = 0\n",
    "    for i in range(0, N):\n",
    "        train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta)\n",
    "        err = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "        tot_eta+=err\n",
    "    print(\"Eta = {}, avg_err = {}\".format(eta, tot_eta/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize over eta, momentum, nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta = 0.0001, momentum = 0.0001, nesterov = False, avg_err = 531.6666666666666\n",
      "Eta = 0.0001, momentum = 0.0001, nesterov = True, avg_err = 476.6666666666667\n",
      "Eta = 0.0001, momentum = 0.001, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.001, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.01, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.01, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.1, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.0001, momentum = 0.1, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.0001, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.0001, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.001, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.001, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.01, nesterov = False, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.01, nesterov = True, avg_err = 470.0\n",
      "Eta = 0.001, momentum = 0.1, nesterov = False, avg_err = 409.6666666666667\n",
      "Eta = 0.001, momentum = 0.1, nesterov = True, avg_err = 296.0\n",
      "Eta = 0.01, momentum = 0.0001, nesterov = False, avg_err = 186.33333333333334\n",
      "Eta = 0.01, momentum = 0.0001, nesterov = True, avg_err = 181.66666666666666\n",
      "Eta = 0.01, momentum = 0.001, nesterov = False, avg_err = 184.0\n",
      "Eta = 0.01, momentum = 0.001, nesterov = True, avg_err = 183.66666666666666\n",
      "Eta = 0.01, momentum = 0.01, nesterov = False, avg_err = 183.33333333333334\n",
      "Eta = 0.01, momentum = 0.01, nesterov = True, avg_err = 183.33333333333334\n",
      "Eta = 0.01, momentum = 0.1, nesterov = False, avg_err = 183.0\n",
      "Eta = 0.01, momentum = 0.1, nesterov = True, avg_err = 183.0\n",
      "Eta = 0.1, momentum = 0.0001, nesterov = False, avg_err = 181.66666666666666\n",
      "Eta = 0.1, momentum = 0.0001, nesterov = True, avg_err = 180.0\n",
      "Eta = 0.1, momentum = 0.001, nesterov = False, avg_err = 180.0\n",
      "Eta = 0.1, momentum = 0.001, nesterov = True, avg_err = 179.66666666666666\n",
      "Eta = 0.1, momentum = 0.01, nesterov = False, avg_err = 179.0\n",
      "Eta = 0.1, momentum = 0.01, nesterov = True, avg_err = 179.33333333333334\n",
      "Eta = 0.1, momentum = 0.1, nesterov = False, avg_err = 180.0\n",
      "Eta = 0.1, momentum = 0.1, nesterov = True, avg_err = 179.0\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 100\n",
    "etas = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "momentum = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "N = 3\n",
    "for eta in etas:\n",
    "    for m in momentum:\n",
    "        for nest in [False, True]:\n",
    "            tot_eta = 0\n",
    "            for i in range(0, N):\n",
    "                train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta, \"SGD\", m, nest)\n",
    "                err = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "                tot_eta+=err\n",
    "            print(\"Eta = {}, momentum = {}, nesterov = {}, avg_err = {}\".format(eta, m, nest, tot_eta/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 250\n",
    "eta = 0.01\n",
    "train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta, \"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, train_input, train_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, test_input, test_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize over eta (simple optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta = 1e-05, avg_err = 280.9\n",
      "Eta = 0.0001, avg_err = 198.2\n",
      "Eta = 0.001, avg_err = 205.6\n",
      "Eta = 0.01, avg_err = 216.1\n",
      "Eta = 0.1, avg_err = 470.0\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "mini_batch_size = 100\n",
    "epochs = 100\n",
    "etas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "N = 10\n",
    "for eta in etas:\n",
    "    tot_eta = 0\n",
    "    for i in range(0, N):\n",
    "        train_model(model, train_input, train_target, mini_batch_size, criterion, epochs, eta, \"Adam\")\n",
    "        err = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "        tot_eta+=err\n",
    "    print(\"Eta = {}, avg_err = {}\".format(eta, tot_eta/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 1, 14, 14]' is invalid for input of size 196000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-fc72384b7eba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_input_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_classes_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_one_hot_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_input_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_classes_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_one_hot_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[10, 1, 14, 14]' is invalid for input of size 196000"
     ]
    }
   ],
   "source": [
    "train_input_left = train_input[:,0,:,:].view(N,1,14,14)\n",
    "train_classes_left = plg.convert_to_one_hot_labels(train_input, train_classes[:,0]).type(torch.LongTensor)\n",
    "test_input_left = test_input[:,0,:,:].view(N,1,14,14)\n",
    "test_classes_left = plg.convert_to_one_hot_labels(test_input, test_classes[:,0]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    \n",
    "    if (torch.cuda.is_available()):\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    model.to(device)\n",
    "    train_input = train_input.to(device)\n",
    "    train_target = train_target.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    eta = 1e-1\n",
    "    epochs = 250\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = eta)\n",
    "    \n",
    "    for e in range(0, epochs):\n",
    "        for input_data, target_data in zip(train_input.split(mini_batch_size), train_target.split(mini_batch_size)):\n",
    "            output = model(input_data)\n",
    "            #print(output)\n",
    "            loss = criterion(output, target_data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k] != predicted_classes[k]:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "if (torch.cuda.is_available()):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "model.to(device)\n",
    "train_model(model, train_input_left, train_classes[:,0], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #2 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-eb007706b898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompute_nb_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-5d63722d00c2>\u001b[0m in \u001b[0;36mcompute_nb_errors\u001b[1;34m(model, input, target, mini_batch_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-3729cbeb8948>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 320\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #2 'weight'"
     ]
    }
   ],
   "source": [
    "compute_nb_errors(model, train_input_left, test_classes[:,0], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
